# Prometheus Alert Rules for DelTran

groups:
  # ==========================================================================
  # Application Alerts
  # ==========================================================================

  - name: application
    interval: 30s
    rules:
      # High error rate
      - alert: HighErrorRate
        expr: |
          (
            rate(gateway_requests_failed_total[5m]) /
            rate(gateway_requests_total[5m])
          ) > 0.01
        for: 5m
        labels:
          severity: critical
          component: gateway
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value | humanizePercentage }} (threshold: 1%)"

      # Low throughput
      - alert: LowThroughput
        expr: rate(gateway_requests_total[5m]) < 1000
        for: 10m
        labels:
          severity: warning
          component: gateway
        annotations:
          summary: "Low throughput"
          description: "Current TPS: {{ $value | humanize }} (target: 1000)"

      # High latency
      - alert: HighLatency
        expr: |
          histogram_quantile(0.95,
            rate(gateway_request_duration_seconds_bucket[5m])
          ) > 0.1
        for: 5m
        labels:
          severity: warning
          component: gateway
        annotations:
          summary: "High latency detected"
          description: "p95 latency: {{ $value | humanizeDuration }} (threshold: 100ms)"

  # ==========================================================================
  # Ledger Alerts
  # ==========================================================================

  - name: ledger
    interval: 30s
    rules:
      # Ledger append failures
      - alert: LedgerAppendFailures
        expr: rate(ledger_append_errors_total[5m]) > 10
        for: 5m
        labels:
          severity: critical
          component: ledger
        annotations:
          summary: "Ledger append failures"
          description: "{{ $value | humanize }} append errors per second"

      # High ledger latency
      - alert: HighLedgerLatency
        expr: |
          histogram_quantile(0.95,
            rate(ledger_append_duration_seconds_bucket[5m])
          ) > 0.01
        for: 5m
        labels:
          severity: warning
          component: ledger
        annotations:
          summary: "High ledger append latency"
          description: "p95 latency: {{ $value | humanizeDuration }} (threshold: 10ms)"

      # Money conservation violation
      - alert: MoneyConservationViolation
        expr: |
          ledger_total_debits != ledger_total_credits
        for: 1m
        labels:
          severity: critical
          component: ledger
        annotations:
          summary: "Money conservation violated"
          description: "Total debits ({{ .Labels.debits }}) != total credits ({{ .Labels.credits }})"

  # ==========================================================================
  # Settlement Alerts
  # ==========================================================================

  - name: settlement
    interval: 30s
    rules:
      # Settlement window missed
      - alert: SettlementWindowMissed
        expr: |
          time() - settlement_last_window_timestamp > 21600
        for: 1m
        labels:
          severity: critical
          component: settlement
        annotations:
          summary: "Settlement window missed"
          description: "No settlement for {{ $value | humanizeDuration }} (expected: 6 hours)"

      # Low netting efficiency
      - alert: LowNettingEfficiency
        expr: settlement_netting_efficiency < 0.70
        for: 10m
        labels:
          severity: warning
          component: settlement
        annotations:
          summary: "Low netting efficiency"
          description: "Current efficiency: {{ $value | humanizePercentage }} (target: 70%)"

  # ==========================================================================
  # Consensus Alerts
  # ==========================================================================

  - name: consensus
    interval: 30s
    rules:
      # Consensus stalled
      - alert: ConsensusStalled
        expr: increase(consensus_height[5m]) == 0
        for: 5m
        labels:
          severity: critical
          component: consensus
        annotations:
          summary: "Consensus has stalled"
          description: "No new blocks in 5 minutes (last height: {{ $value }})"

      # Validator offline
      - alert: ValidatorOffline
        expr: up{job="consensus"} == 0
        for: 2m
        labels:
          severity: critical
          component: consensus
        annotations:
          summary: "Validator {{ $labels.instance }} is offline"
          description: "Validator has been down for 2 minutes"

      # Too many validators offline
      - alert: TooManyValidatorsOffline
        expr: count(up{job="consensus"} == 0) >= 3
        for: 1m
        labels:
          severity: critical
          component: consensus
        annotations:
          summary: "Too many validators offline"
          description: "{{ $value }} validators offline (max tolerated: 2)"

      # High block time
      - alert: HighBlockTime
        expr: |
          rate(consensus_block_interval_seconds_sum[5m]) /
          rate(consensus_block_interval_seconds_count[5m]) > 10
        for: 5m
        labels:
          severity: warning
          component: consensus
        annotations:
          summary: "High block time"
          description: "Average block time: {{ $value | humanizeDuration }} (target: 6s)"

  # ==========================================================================
  # System Alerts
  # ==========================================================================

  - name: system
    interval: 30s
    rules:
      # High CPU usage
      - alert: HighCPUUsage
        expr: |
          100 - (avg by (instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 10m
        labels:
          severity: warning
          component: system
        annotations:
          summary: "High CPU usage on {{ $labels.instance }}"
          description: "CPU usage: {{ $value | humanize }}%"

      # High memory usage
      - alert: HighMemoryUsage
        expr: |
          (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 85
        for: 10m
        labels:
          severity: warning
          component: system
        annotations:
          summary: "High memory usage on {{ $labels.instance }}"
          description: "Memory usage: {{ $value | humanize }}%"

      # Disk space low
      - alert: DiskSpaceLow
        expr: |
          (1 - (node_filesystem_avail_bytes{mountpoint="/"} / node_filesystem_size_bytes{mountpoint="/"})) * 100 > 80
        for: 10m
        labels:
          severity: warning
          component: system
        annotations:
          summary: "Low disk space on {{ $labels.instance }}"
          description: "Disk usage: {{ $value | humanize }}%"

      # Disk will fill in 4 hours
      - alert: DiskWillFillSoon
        expr: |
          predict_linear(node_filesystem_avail_bytes{mountpoint="/"}[1h], 4*3600) < 0
        for: 10m
        labels:
          severity: critical
          component: system
        annotations:
          summary: "Disk will fill in 4 hours on {{ $labels.instance }}"
          description: "Disk is filling rapidly"

  # ==========================================================================
  # Security Alerts
  # ==========================================================================

  - name: security
    interval: 30s
    rules:
      # Rate limit exceeded frequently
      - alert: FrequentRateLimitExceeded
        expr: rate(rate_limiter_denied_total[5m]) > 100
        for: 5m
        labels:
          severity: warning
          component: security
        annotations:
          summary: "Frequent rate limit denials"
          description: "{{ $value | humanize }} denials per second (possible attack)"

      # Authentication failures
      - alert: HighAuthenticationFailures
        expr: rate(auth_failures_total[5m]) > 10
        for: 5m
        labels:
          severity: warning
          component: security
        annotations:
          summary: "High authentication failure rate"
          description: "{{ $value | humanize }} failures per second"

      # TLS certificate expiring soon
      - alert: TLSCertificateExpiringSoon
        expr: tls_certificate_expiry_days < 30
        for: 1h
        labels:
          severity: warning
          component: security
        annotations:
          summary: "TLS certificate expiring soon"
          description: "Certificate expires in {{ $value }} days"

      # Audit log integrity failure
      - alert: AuditLogIntegrityFailure
        expr: audit_log_integrity_checks_failed_total > 0
        for: 1m
        labels:
          severity: critical
          component: security
        annotations:
          summary: "Audit log integrity check failed"
          description: "Possible tampering detected"

  # ==========================================================================
  # Business Metrics Alerts
  # ==========================================================================

  - name: business
    interval: 1m
    rules:
      # Unusual payment volume
      - alert: UnusualPaymentVolume
        expr: |
          (
            rate(payments_total[1h]) >
            (avg_over_time(rate(payments_total[1h])[7d:1h]) + 3 * stddev_over_time(rate(payments_total[1h])[7d:1h]))
          )
        for: 10m
        labels:
          severity: warning
          component: business
        annotations:
          summary: "Unusual payment volume detected"
          description: "Payment rate: {{ $value | humanize }} (3Ïƒ above normal)"

      # Large payment
      - alert: LargePaymentDetected
        expr: payment_amount_dollars > 1000000
        labels:
          severity: info
          component: business
        annotations:
          summary: "Large payment detected"
          description: "Payment amount: ${{ $value | humanize }} (>$1M)"